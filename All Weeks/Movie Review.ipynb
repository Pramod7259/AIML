{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f601473f-5451-4310-866f-e5842a257c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the `re` module for regular expression operations (e.g., text preprocessing).\n",
    "\n",
    "import re\n",
    "\n",
    "# Importing `pandas` for data manipulation and analysis.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Importing `numpy` for numerical computations and handling arrays.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Importing `LabelEncoder` from sklearn for encoding target labels into numerical format.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Importing `train_test_split` to split the dataset into training and testing subsets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing the main `keras` library to build and train deep learning models.\n",
    "\n",
    "import keras\n",
    "\n",
    "# Importing `classification_report` to evaluate the performance of the model by generating detailed classification metrics.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Importing `accuracy_score` to compute the accuracy of the classification model.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Importing `math` for mathematical operations (e.g., logarithms, square roots, etc.).\n",
    "\n",
    "import math\n",
    "\n",
    "# Importing `nltk`, a natural language processing library, for tasks such as tokenization, stemming, and stopword removal.\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4393046-2e3c-475d-a81d-d1517a57599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the Warning\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4b22b-5319-4343-b60c-a0faa00b229a",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4f71f4-5362-4ba5-ab6c-d589f59214bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:/Users/Pramoda A S/Desktop/AIML Documents/DataSets in CSV files/Movie Review Dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7183283-adc4-466b-8a1c-a92993243591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick any random Review\n",
    "\n",
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e859c68-b242-4822-be42-82a9177d6086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ef2e16-d049-439b-990d-3c41b91c28cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment count\n",
    "\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b8158f-00ff-4fff-bb5f-8d4f75261ba0",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0941b56-2ecc-4772-947b-efbd7d0cb3dd",
   "metadata": {},
   "source": [
    "### Remove HTML tags, URLs, non-alphanumeric characters & Convert to lowercasev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f80b70-d5b6-4249-b85b-9825c264f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def remove_tags(string):\n",
    "\n",
    "    removelist = \"\"  # Add any characters you'd like to keep\n",
    "\n",
    "    # Remove HTML tags\n",
    "\n",
    "    result = re.sub(r'<[^>]+>', '', string)\n",
    "\n",
    "    # Remove URLs\n",
    "\n",
    "    result = re.sub(r'https?://\\S+', '', result)\n",
    "\n",
    "    # Remove non-alphanumeric characters (except for those in the removelist)\n",
    "\n",
    "    result = re.sub(r'[^a-zA-Z0-9' + removelist + r'\\s]', ' ', result)\n",
    "\n",
    "    # Convert to lowercase\n",
    "\n",
    "    result = result.lower()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6931e4-8e44-4283-b4f3-12f99d941fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " movie 1 actor   aamir khan click here to download\n"
     ]
    }
   ],
   "source": [
    "string = \"<html><body><p> Movie 1</p><p> Actor - Aamir Khan</p><p> Click here to <a href='http://google.com'>download</a></p></body></html>\"\n",
    "\n",
    "print(remove_tags(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eefa2b91-b0bc-4c0d-b101-c2a7b2c55c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check out my notebook \n"
     ]
    }
   ],
   "source": [
    "#Suppose we have the FOllowing Text With URL.\n",
    "\n",
    "string1 = 'Check out my notebook https://www.kaggle.com/campusx/notebook8223fc1abb'\n",
    "\n",
    "print(remove_tags(string1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a93f5157-1b0f-42a6-8c13-e03b4aaf8737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quick brown fox jumps over the lazy dog  however  the dog doesn t seem impressed  oh no  it just yawned  how disappointing  maybe a squirrel would elicit a reaction  alas  the fox is out of luck \n"
     ]
    }
   ],
   "source": [
    "# Text With Punctuation.\n",
    "\n",
    "string2 = \"The quick brown fox jumps over the lazy dog. However, the dog doesn't seem impressed! Oh no, it just yawned. How disappointing! Maybe a squirrel would elicit a reaction. Alas, the fox is out of luck.\"\n",
    "\n",
    "# Remove Punctuation.\n",
    "\n",
    "print(remove_tags(string2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1b4a72e-c618-442a-bfb5-cc256d2aedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Function to Remove HTML Tags in our Dataset Colum Review.\n",
    "\n",
    "df['review'] = df['review'].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0785b56-b318-45ae-a895-ef5ad484255f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basically there s a family where a little boy  jake  thinks there s a zombie in his closet   his parents are fighting all the time this movie is slower than a soap opera    and suddenly  jake decides to become rambo and kill the zombie ok  first of all when you re going to make a film you must decide if its a thriller or a drama  as a drama the movie is watchable  parents are divorcing   arguing like in real life  and then we have jake with his closet which totally ruins all the film  i expected to see a boogeyman similar movie  and instead i watched a drama with some meaningless thriller spots 3 out of 10 just for the well playing parents   descent dialogs  as for the shots with jake  just ignore them '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed93b71-a170-4fb8-a81c-ccda54626135",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e4b7ec1-9e1a-47e8-9f4f-8fc68b0eb89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db04d3fc-6b5c-4ee7-847e-2537b8c2d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "\n",
    "# Download required NLTK resources\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize tokenizer and lemmatizer\n",
    "\n",
    "w_tokenizer = WhitespaceTokenizer()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de0b26e-58ce-4e3e-b460-a0aec32f9700",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a8ecb40-d120-4ede-b67e-d698a0962421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lemmatization function\n",
    "\n",
    "def lemmatize_text(text):\n",
    "\n",
    "    # Tokenize and lemmatize in a single step using a list comprehension\n",
    "\n",
    "    lemmatized = [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "    # Join the lemmatized tokens back into a string\n",
    "\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "\n",
    "\n",
    "# Apply the function to the 'review' column\n",
    "\n",
    "df['review'] = df['review'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbf303d4-ec07-437c-bb1a-5a6b33768119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of each review :  119.5824\n",
      "Percentage of reviews with positive sentiment is 50.0%\n",
      "Percentage of reviews with negative sentiment is 50.0%\n"
     ]
    }
   ],
   "source": [
    "# Initialize a variable to store the total word count\n",
    "\n",
    "s = 0.0\n",
    "\n",
    "# Loop through each review in the 'review' column\n",
    "\n",
    "for i in df['review']:\n",
    "\n",
    "    # Split the review into a list of words\n",
    "\n",
    "    word_list = i.split()\n",
    "\n",
    "    # Add the number of words in the current review to the total word count\n",
    "\n",
    "    s = s + len(word_list)\n",
    "\n",
    "# Calculate the average review length by dividing the total word count by the number of reviews\n",
    "\n",
    "print(\"Average length of each review : \", s / df.shape[0])\n",
    "\n",
    "# Initialize a counter for positive sentiment reviews\n",
    "\n",
    "pos = 0\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "\n",
    "    # Check if the sentiment of the current review is 'positive'\n",
    "\n",
    "    if df.iloc[i]['sentiment'] == 'positive':\n",
    "\n",
    "        # Increment the positive sentiment counter\n",
    "\n",
    "        pos = pos + 1\n",
    "\n",
    "# Calculate the number of negative sentiment reviews\n",
    "\n",
    "neg = df.shape[0] - pos\n",
    "\n",
    "# Calculate and print the percentage of positive sentiment reviews\n",
    "\n",
    "print(\"Percentage of reviews with positive sentiment is \" + str(pos / df.shape[0] * 100) + \"%\")\n",
    "\n",
    "# Calculate and print the percentage of negative sentiment reviews\n",
    "\n",
    "print(\"Percentage of reviews with negative sentiment is \" + str(neg / df.shape[0] * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6debc074-e493-412d-a5f3-80023a9fc094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching 1 oz episode h...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewer mentioned watching 1 oz episode h...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  thought wonderful way spend time hot summer we...  positive\n",
       "3  basically family little boy jake think zombie ...  negative\n",
       "4  petter mattei love time money visually stunnin...  positive"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03182d0e-62c2-4e7a-b157-a1202039ba03",
   "metadata": {},
   "source": [
    "### Encoding Labels and Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ec0f070-c551-4c5e-bbc7-d4ed4b67565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['review'].values\n",
    "\n",
    "labels = df['sentiment'].values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoded_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ace07f9b-b34a-4375-8802-0a914b2b8cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,) (40000,)\n",
      "(10000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#split the dataset\n",
    "\n",
    "#train dataset\n",
    "\n",
    "train_reviews=df.review[:40000]\n",
    "\n",
    "train_sentiments=df.sentiment[:40000]\n",
    "\n",
    "#test dataset\n",
    "\n",
    "test_reviews=df.review[40000:]\n",
    "\n",
    "test_sentiments=df.sentiment[40000:]\n",
    "\n",
    "print(train_reviews.shape,train_sentiments.shape)\n",
    "\n",
    "print(test_reviews.shape,test_sentiments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c267b53b-9b3c-4e20-b742-f2fdca21169c",
   "metadata": {},
   "source": [
    "## Spelling Correction\n",
    "### involves identifying and correcting misspelled words in a piece of text. It's a crucial step in many Natural Language Processing (NLP) tasks like text cleaning, search engines, chatbots, and more. Correcting spelling mistakes ensures the data is clean, improves readability, and enhances the performance of machine learning models\n",
    "\n",
    "## How Spelling Correction Works\n",
    "\n",
    "## Detect Misspelled Words\n",
    "\n",
    "## Identify words in the text that are not valid according to a dictionary or linguistic model.\n",
    "\n",
    "## Suggest Corrections\n",
    "\n",
    "## Provide the closest valid word(s) based on the identified error.\n",
    "\n",
    "## Replace the Word\n",
    "\n",
    "## Replace the misspelled word with the most suitable correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d3279a3-0550-40d5-9986-20a13742ad7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'indexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspellchecker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpellChecker\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcorrect_spelling\u001b[39m(text):\n\u001b[32m      7\u001b[39m     spell = SpellChecker()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\spellchecker\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m  \u001b[39m\u001b[34;01mspellchecker\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Spellchecker,getInstance\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\spellchecker\\core.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minexactsearch\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mindexer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DictionaryIndex\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangdetect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _detect_lang\n\u001b[32m     29\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mSpellchecker\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgetInstance\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'indexer'"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "\n",
    "\n",
    "def correct_spelling(text):\n",
    "\n",
    "    spell = SpellChecker()\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    corrected_words = []\n",
    "\n",
    "\n",
    "\n",
    "    for word in words:\n",
    "\n",
    "        corrected = spell.correction(word)\n",
    "\n",
    "        # If correction is None, use the original word\n",
    "\n",
    "        corrected_words.append(corrected if corrected else word)\n",
    "\n",
    "\n",
    "\n",
    "    return \" \".join(corrected_words)\n",
    "\n",
    "\n",
    "\n",
    "# Apply spelling correction\n",
    "\n",
    "train_reviews = [correct_spelling(review) for review in train_reviews]\n",
    "\n",
    "test_reviews = [correct_spelling(review) for review in test_reviews] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219e3b1-b34f-498d-96ff-b2ead2dfaa20",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49649a6-11f6-49ac-aeb0-c30242a7ca49",
   "metadata": {},
   "source": [
    "### Bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fda4ae7-4703-4d5e-9608-3f139589e12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (40000, 6856109)\n",
      "BOW_cv_test: (10000, 6856109)\n",
      "Vocabulary size: 6856109\n"
     ]
    }
   ],
   "source": [
    "# Import the required class\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# CountVectorizer for bag-of-words representation\n",
    "\n",
    "# Using valid min_df and max_df values\n",
    "\n",
    "cv = CountVectorizer(min_df=1, max_df=0.95, binary=False, ngram_range=(1, 3))\n",
    "\n",
    "\n",
    "\n",
    "# Fit and transform the train reviews\n",
    "\n",
    "cv_train_reviews = cv.fit_transform(train_reviews)\n",
    "\n",
    "\n",
    "\n",
    "# Transform the test reviews\n",
    "\n",
    "cv_test_reviews = cv.transform(test_reviews)\n",
    "\n",
    "\n",
    "\n",
    "# Output the shapes\n",
    "\n",
    "print('BOW_cv_train:', cv_train_reviews.shape)\n",
    "\n",
    "print('BOW_cv_test:', cv_test_reviews.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Vocabulary size\n",
    "\n",
    "vocab = cv.get_feature_names_out()\n",
    "\n",
    "print('Vocabulary size:', len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b46b22-539c-4f5f-9e30-c3915896953c",
   "metadata": {},
   "source": [
    "## Tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066107e8-d56c-4049-b1e0-9427d764c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required class\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=1, max_df=0.95, use_idf=True, ngram_range=(1, 3))\n",
    "\n",
    "\n",
    "\n",
    "# Fit and transform the train reviews\n",
    "\n",
    "tv_train_reviews = tv.fit_transform(train_reviews)\n",
    "\n",
    "\n",
    "\n",
    "# Transform the test reviews\n",
    "\n",
    "tv_test_reviews = tv.transform(test_reviews)\n",
    "\n",
    "\n",
    "\n",
    "# Output the shapes\n",
    "\n",
    "print('Tfidf_train:', tv_train_reviews.shape)\n",
    "\n",
    "print('Tfidf_test:', tv_test_reviews.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Vocabulary size\n",
    "\n",
    "vocab = tv.get_feature_names_out()\n",
    "\n",
    "print('Vocabulary size:', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a29b0-5602-4abc-925c-09fd850521f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e4b481-15d3-4569-8cfa-a7c12f2a8d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already encoded your labels\n",
    "\n",
    "# reviews = data['review'].values\n",
    "\n",
    "# labels = data['sentiment'].values\n",
    "\n",
    "\n",
    "\n",
    "# Encode sentiments\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoded_labels = encoder.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60f442-9ae0-4f1f-98a6-d4065acc2cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test\n",
    "\n",
    "train_reviews = df['review'][:40000]\n",
    "\n",
    "train_sentiments = encoded_labels[:40000]\n",
    "\n",
    "test_reviews = df['review'][40000:]\n",
    "\n",
    "test_sentiments = encoded_labels[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ef0ab0-0ba3-484b-953b-fb10c2d3d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure shapes\n",
    "\n",
    "print(train_reviews.shape, train_sentiments.shape)\n",
    "\n",
    "print(test_reviews.shape, test_sentiments.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b9191-be6f-464b-a7a0-6adeea1e18fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the reviews (you can choose CountVectorizer or TfidfVectorizer)\n",
    "\n",
    "# Using CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=1, max_df=0.95, ngram_range=(1, 3))\n",
    "\n",
    "cv_train_reviews = cv.fit_transform(train_reviews)\n",
    "\n",
    "cv_test_reviews = cv.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24eda6-2129-4e88-936a-5cb480e40506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use TfidfVectorizer\n",
    "\n",
    "# tv = TfidfVectorizer(min_df=1, max_df=0.95, ngram_range=(1, 3))\n",
    "\n",
    "# tv_train_reviews = tv.fit_transform(train_reviews)\n",
    "\n",
    "# tv_test_reviews = tv.transform(test_reviews)\n",
    "\n",
    "\n",
    "\n",
    "# Train-Test Split (if not already split)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(cv_train_reviews, train_sentiments, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff6321-68b7-4bb1-8051-f83689f94fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "svc = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81497e11-6227-4837-9839-5da737d3ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb79c0-1319-4c63-8c11-50cc76ec9cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918a9cb-cbc4-417e-9549-5b8e53f98968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "svc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298ad59-aaa4-4e6e-a3d9-944482227a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "\n",
    "logreg_preds = logreg.predict(X_val)\n",
    "\n",
    "nb_preds = nb.predict(X_val)\n",
    "\n",
    "svc_preds = svc.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4e20f-e2e3-47d4-91ee-febc390d5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "\n",
    "print(\"Logistic Regression Accuracy: \", accuracy_score(y_val, logreg_preds))\n",
    "\n",
    "print(\"Naive Bayes Accuracy: \", accuracy_score(y_val, nb_preds))\n",
    "\n",
    "print(\"SVM Accuracy: \", accuracy_score(y_val, svc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db450f-db3f-422a-b4e7-6c055582b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification reports\n",
    "\n",
    "print(\"Logistic Regression Classification Report: \")\n",
    "\n",
    "print(classification_report(y_val, logreg_preds))\n",
    "\n",
    "print(\"Naive Bayes Classification Report: \")\n",
    "\n",
    "print(classification_report(y_val, nb_preds))\n",
    "\n",
    "print(\"SVM Classification Report: \")\n",
    "\n",
    "print(classification_report(y_val, svc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a223033-e115-4863-8e16-b51f16155dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bde8f-3189-41f6-8bc4-fa0abf39cffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d24fdb4-eb9b-4585-90e9-9f9038b7284e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
