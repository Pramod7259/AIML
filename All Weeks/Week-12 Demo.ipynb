{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "079f0748-ff10-4d91-ac36-77532a250fec",
   "metadata": {},
   "source": [
    "# Write a NLP Program to demostrate following tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65c274-a081-457c-96d7-d0dbe3e9c18f",
   "metadata": {},
   "source": [
    "## a. Tokenization removal of stop words, punchuation, POS & NER Tags\n",
    "## b. Bag of Words, TF-IDF Vectorisation & Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241a339-7347-4e97-9893-2293740f624e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a581eda-fe20-4607-99e7-2759e82328a5",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c83105-976a-4de0-9c54-4bf86506a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92335409-83fc-47d7-9a7f-157c32830ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ca53d8e-f91f-423a-99c7-85ae5ac3563d",
   "metadata": {},
   "source": [
    "## Download required NLTK resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f8cf4f-1315-431f-8d4a-0a11440b260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28874ea1-fd3a-4407-bfe3-a406c6a90ebd",
   "metadata": {},
   "source": [
    "## Sample Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35e9dc7-5c17-48fe-8303-e40d868b468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Apple is looking at buying U.K. startup for $1 billion. \n",
    "          Artificial Intelligence is the future of technology!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821ab422-c10d-41e4-9aef-99d4314cb696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd535970-5aca-4138-8e24-1099ba650577",
   "metadata": {},
   "source": [
    "## a) Tokenization, Stop Words & Punctuation Removal\n",
    "\n",
    "#   ------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400def53-d1e6-4942-bf27-6a40bdbd7a6f",
   "metadata": {},
   "source": [
    "## Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c871c8-05d8-4608-b8f8-926b0b4e21bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87738f3-7922-4b44-b5bc-2b7ab21fb024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tokens ---\n",
      "['Apple', 'is', 'looking', 'at', 'buying', 'U.K.', 'startup', 'for', '$', '1', 'billion', '.', 'Artificial', 'Intelligence', 'is', 'the', 'future', 'of', 'technology', '!']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "print(\"--- Tokens ---\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63baaf64-a8b5-44db-bc0a-afdd6911d7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49a3453e-cb93-4532-9e21-eafce20dc954",
   "metadata": {},
   "source": [
    "## Remove stop words and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a235637-1b1e-4b05-99bc-55f431644beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation_regex = re.compile(r'[\\W_]+')  # matches punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1bbf549-62ff-48cb-8741-cee0e5bd7a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tokens after Stopword & Punctuation Removal ---\n",
      "['Apple', 'looking', 'buying', 'U.K.', 'startup', '1', 'billion', 'Artificial', 'Intelligence', 'future', 'technology']\n"
     ]
    }
   ],
   "source": [
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words and not punctuation_regex.match(word)]\n",
    "print(\"\\n--- Tokens after Stopword & Punctuation Removal ---\")\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090b1c1-97f6-4494-b18b-800bb5962030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca5bd19c-5c63-4ea0-af8e-68807544eb5f",
   "metadata": {},
   "source": [
    "## Part A: POS Tagging & NER using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b108d5ca-8db6-49c7-afda-b8eb493d9f42",
   "metadata": {},
   "source": [
    "#    ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44d869d2-9928-42f5-a93e-40bcceb907d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')  # Load small English model\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40209727-cfab-4376-a256-b9c162cbfed9",
   "metadata": {},
   "source": [
    "## POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5244236-0927-4348-84b4-9d68e89fbba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- POS Tagging ---\n",
      "Apple        --> PROPN\n",
      "is           --> AUX\n",
      "looking      --> VERB\n",
      "at           --> ADP\n",
      "buying       --> VERB\n",
      "U.K.         --> PROPN\n",
      "startup      --> VERB\n",
      "for          --> ADP\n",
      "$            --> SYM\n",
      "1            --> NUM\n",
      "billion      --> NUM\n",
      ".            --> PUNCT\n",
      "\n",
      "            --> SPACE\n",
      "Artificial   --> PROPN\n",
      "Intelligence --> PROPN\n",
      "is           --> AUX\n",
      "the          --> DET\n",
      "future       --> NOUN\n",
      "of           --> ADP\n",
      "technology   --> NOUN\n",
      "!            --> PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- POS Tagging ---\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<12} --> {token.pos_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de45af28-4d44-40e3-a606-fc55b6614dad",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd531100-7c09-40b5-9af7-31de4e5931a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Named Entities ---\n",
      "Apple           --> ORG\n",
      "U.K.            --> GPE\n",
      "$1 billion      --> MONEY\n",
      "Artificial Intelligence --> PERSON\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Named Entities ---\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:<15} --> {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea74be-d2e7-4989-9c29-a381a3ea7760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "902bf46d-a7e6-41a8-8b91-1d8a531b2f1d",
   "metadata": {},
   "source": [
    "## -------------------------------\n",
    "Part B: Bag of Words & TF-IDF Vectorization\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e9c35f-42aa-4bb7-b905-bfe3d4f551b1",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1086a16a-389a-4f38-b491-220dd354fc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Bag of Words ---\n",
      "['apple' 'artificial' 'at' 'billion' 'buying' 'for' 'future'\n",
      " 'intelligence' 'is' 'looking' 'of' 'startup' 'technology' 'the']\n",
      "[[1 1 1 1 1 1 1 1 2 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform([text])\n",
    "print(\"\\n--- Bag of Words ---\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(bow.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b100873-f147-442f-890b-13820c2e20c6",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91a3f304-ca78-44ce-8a05-14ee729d40dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TF-IDF ---\n",
      "['apple' 'artificial' 'at' 'billion' 'buying' 'for' 'future'\n",
      " 'intelligence' 'is' 'looking' 'of' 'startup' 'technology' 'the']\n",
      "[[0.24253563 0.24253563 0.24253563 0.24253563 0.24253563 0.24253563\n",
      "  0.24253563 0.24253563 0.48507125 0.24253563 0.24253563 0.24253563\n",
      "  0.24253563 0.24253563]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform([text])\n",
    "print(\"\\n--- TF-IDF ---\")\n",
    "print(tfidf_vectorizer.get_feature_names_out())\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd090c63-a883-41b3-a2c2-5f0166caee4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf0d597a-567b-4a7d-8279-f2dcbe356f67",
   "metadata": {},
   "source": [
    "## -------------------------------\n",
    "Part B: N-grams (Bigrams and Trigrams)\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d2dd454-8124-4601-97a2-bb7701fbcd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- N-grams (Bigrams and Trigrams) ---\n",
      "['apple is' 'apple is looking' 'artificial intelligence'\n",
      " 'artificial intelligence is' 'at buying' 'at buying startup'\n",
      " 'billion artificial' 'billion artificial intelligence' 'buying startup'\n",
      " 'buying startup for' 'for billion' 'for billion artificial' 'future of'\n",
      " 'future of technology' 'intelligence is' 'intelligence is the'\n",
      " 'is looking' 'is looking at' 'is the' 'is the future' 'looking at'\n",
      " 'looking at buying' 'of technology' 'startup for' 'startup for billion'\n",
      " 'the future' 'the future of']\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(ngram_range=(2, 3))\n",
    "ngrams = ngram_vectorizer.fit_transform([text])\n",
    "print(\"\\n--- N-grams (Bigrams and Trigrams) ---\")\n",
    "print(ngram_vectorizer.get_feature_names_out())\n",
    "print(ngrams.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cee897-f6e7-42fc-a6e2-7e5c62734a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b76c8-3e1c-40ff-84b6-e5eae960ae55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
