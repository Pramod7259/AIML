{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9809816-37e2-4e05-8264-44c8a79de942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries \n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a5dff27-0cbe-47bc-b982-688d215a08d2",
   "metadata": {},
   "source": [
    "# Download NLTK resources (first time only)\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c5380ce-150a-45f4-8e10-2c9dda7c7626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "ML model monitoring is the practice of tracking the performance of ML models in production to identify potential issues that can add negative business value. These practices help proactively monitor prediction quality issues, data relevance, model accuracy, and bias.\n",
      "\n",
      "ML monitoring constitutes the subset of AI observability where it showcases a bigger picture with testing, validation, explainability, and exploring unforeseen failure modes.\n",
      "The performance of ML models starts degrading over time. It can be due to data inconsistencies, skews, and drifts, making deployed models inaccurate and irrelevant. Appropriate ML monitoring helps identify precisely when the model performance started diminishing. Such proactive monitoring helps take required actions like retraining models or replacing models. It helps foster usersâ€™ trust in ML systems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample text\n",
    "\n",
    "df=open(\"C:/Users/Pramoda A S/Desktop/AIML Documents/nlpEx.txt\")\n",
    "text=df.read()\n",
    "\n",
    "print(\"Original Text:\")\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4533e7ea-f8a5-46a2-95db-83ef3b96225f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Tokens:\n",
      "['ML', 'model', 'monitoring', 'is', 'the', 'practice', 'of', 'tracking', 'the', 'performance', 'of', 'ML', 'models', 'in', 'production', 'to', 'identify', 'potential', 'issues', 'that', 'can', 'add', 'negative', 'business', 'value', '.', 'These', 'practices', 'help', 'proactively', 'monitor', 'prediction', 'quality', 'issues', ',', 'data', 'relevance', ',', 'model', 'accuracy', ',', 'and', 'bias', '.', 'ML', 'monitoring', 'constitutes', 'the', 'subset', 'of', 'AI', 'observability', 'where', 'it', 'showcases', 'a', 'bigger', 'picture', 'with', 'testing', ',', 'validation', ',', 'explainability', ',', 'and', 'exploring', 'unforeseen', 'failure', 'modes', '.', 'The', 'performance', 'of', 'ML', 'models', 'starts', 'degrading', 'over', 'time', '.', 'It', 'can', 'be', 'due', 'to', 'data', 'inconsistencies', ',', 'skews', ',', 'and', 'drifts', ',', 'making', 'deployed', 'models', 'inaccurate', 'and', 'irrelevant', '.', 'Appropriate', 'ML', 'monitoring', 'helps', 'identify', 'precisely', 'when', 'the', 'model', 'performance', 'started', 'diminishing', '.', 'Such', 'proactive', 'monitoring', 'helps', 'take', 'required', 'actions', 'like', 'retraining', 'models', 'or', 'replacing', 'models', '.', 'It', 'helps', 'foster', 'usersâ€™', 'trust', 'in', 'ML', 'systems', '.']\n"
     ]
    }
   ],
   "source": [
    "# 1. Tokenization (NLTK)\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(\"1. Tokens:\")\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c843687-ef5e-447a-9cdf-d76532c854c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. After Stopword Removal:\n",
      "['ML', 'model', 'monitoring', 'practice', 'tracking', 'performance', 'ML', 'models', 'production', 'identify', 'potential', 'issues', 'add', 'negative', 'business', 'value', 'practices', 'help', 'proactively', 'monitor', 'prediction', 'quality', 'issues', 'data', 'relevance', 'model', 'accuracy', 'bias', 'ML', 'monitoring', 'constitutes', 'subset', 'AI', 'observability', 'showcases', 'bigger', 'picture', 'testing', 'validation', 'explainability', 'exploring', 'unforeseen', 'failure', 'modes', 'performance', 'ML', 'models', 'starts', 'degrading', 'time', 'due', 'data', 'inconsistencies', 'skews', 'drifts', 'making', 'deployed', 'models', 'inaccurate', 'irrelevant', 'Appropriate', 'ML', 'monitoring', 'helps', 'identify', 'precisely', 'model', 'performance', 'started', 'diminishing', 'proactive', 'monitoring', 'helps', 'take', 'required', 'actions', 'like', 'retraining', 'models', 'replacing', 'models', 'helps', 'foster', 'trust', 'ML', 'systems']\n"
     ]
    }
   ],
   "source": [
    "# 2. Stopword Removal\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word.isalnum()]\n",
    "print(\"2. After Stopword Removal:\")\n",
    "print(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65e7b1fa-e861-4ebe-a859-c389e7d5843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. POS Tagging:\n",
      "ML              PROPN      NNP\n",
      "model           NOUN       NN\n",
      "monitoring      NOUN       NN\n",
      "is              AUX        VBZ\n",
      "the             DET        DT\n",
      "practice        NOUN       NN\n",
      "of              ADP        IN\n",
      "tracking        VERB       VBG\n",
      "the             DET        DT\n",
      "performance     NOUN       NN\n",
      "of              ADP        IN\n",
      "ML              PROPN      NNP\n",
      "models          NOUN       NNS\n",
      "in              ADP        IN\n",
      "production      NOUN       NN\n",
      "to              PART       TO\n",
      "identify        VERB       VB\n",
      "potential       ADJ        JJ\n",
      "issues          NOUN       NNS\n",
      "that            PRON       WDT\n",
      "can             AUX        MD\n",
      "add             VERB       VB\n",
      "negative        ADJ        JJ\n",
      "business        NOUN       NN\n",
      "value           NOUN       NN\n",
      ".               PUNCT      .\n",
      "These           DET        DT\n",
      "practices       NOUN       NNS\n",
      "help            AUX        VBP\n",
      "proactively     ADV        RB\n",
      "monitor         VERB       VB\n",
      "prediction      NOUN       NN\n",
      "quality         NOUN       NN\n",
      "issues          NOUN       NNS\n",
      ",               PUNCT      ,\n",
      "data            NOUN       NNS\n",
      "relevance       NOUN       NN\n",
      ",               PUNCT      ,\n",
      "model           NOUN       NN\n",
      "accuracy        NOUN       NN\n",
      ",               PUNCT      ,\n",
      "and             CCONJ      CC\n",
      "bias            NOUN       NN\n",
      ".               PUNCT      .\n",
      "\n",
      "\n",
      "              SPACE      _SP\n",
      "ML              PROPN      NNP\n",
      "monitoring      NOUN       NN\n",
      "constitutes     VERB       VBZ\n",
      "the             DET        DT\n",
      "subset          NOUN       NN\n",
      "of              ADP        IN\n",
      "AI              PROPN      NNP\n",
      "observability   NOUN       NN\n",
      "where           SCONJ      WRB\n",
      "it              PRON       PRP\n",
      "showcases       VERB       VBZ\n",
      "a               DET        DT\n",
      "bigger          ADJ        JJR\n",
      "picture         NOUN       NN\n",
      "with            ADP        IN\n",
      "testing         NOUN       NN\n",
      ",               PUNCT      ,\n",
      "validation      NOUN       NN\n",
      ",               PUNCT      ,\n",
      "explainability  NOUN       NN\n",
      ",               PUNCT      ,\n",
      "and             CCONJ      CC\n",
      "exploring       VERB       VBG\n",
      "unforeseen      ADJ        JJ\n",
      "failure         NOUN       NN\n",
      "modes           VERB       VBZ\n",
      ".               PUNCT      .\n",
      "\n",
      "               SPACE      _SP\n",
      "The             DET        DT\n",
      "performance     NOUN       NN\n",
      "of              ADP        IN\n",
      "ML              PROPN      NNP\n",
      "models          NOUN       NNS\n",
      "starts          VERB       VBZ\n",
      "degrading       VERB       VBG\n",
      "over            ADP        IN\n",
      "time            NOUN       NN\n",
      ".               PUNCT      .\n",
      "It              PRON       PRP\n",
      "can             AUX        MD\n",
      "be              AUX        VB\n",
      "due             ADJ        JJ\n",
      "to              ADP        IN\n",
      "data            NOUN       NNS\n",
      "inconsistencies NOUN       NNS\n",
      ",               PUNCT      ,\n",
      "skews           NOUN       NNS\n",
      ",               PUNCT      ,\n",
      "and             CCONJ      CC\n",
      "drifts          NOUN       NNS\n",
      ",               PUNCT      ,\n",
      "making          VERB       VBG\n",
      "deployed        VERB       VBN\n",
      "models          NOUN       NNS\n",
      "inaccurate      ADJ        JJ\n",
      "and             CCONJ      CC\n",
      "irrelevant      ADJ        JJ\n",
      ".               PUNCT      .\n",
      "Appropriate     ADJ        JJ\n",
      "ML              PROPN      NNP\n",
      "monitoring      NOUN       NN\n",
      "helps           VERB       VBZ\n",
      "identify        VERB       VB\n",
      "precisely       ADV        RB\n",
      "when            SCONJ      WRB\n",
      "the             DET        DT\n",
      "model           NOUN       NN\n",
      "performance     NOUN       NN\n",
      "started         VERB       VBD\n",
      "diminishing     VERB       VBG\n",
      ".               PUNCT      .\n",
      "Such            ADJ        JJ\n",
      "proactive       ADJ        JJ\n",
      "monitoring      NOUN       NN\n",
      "helps           VERB       VBZ\n",
      "take            VERB       VB\n",
      "required        VERB       VBN\n",
      "actions         NOUN       NNS\n",
      "like            ADP        IN\n",
      "retraining      VERB       VBG\n",
      "models          NOUN       NNS\n",
      "or              CCONJ      CC\n",
      "replacing       VERB       VBG\n",
      "models          NOUN       NNS\n",
      ".               PUNCT      .\n",
      "It              PRON       PRP\n",
      "helps           VERB       VBZ\n",
      "foster          VERB       VB\n",
      "usersâ€         PROPN      NNP\n",
      "™               ADJ        JJ\n",
      "trust           NOUN       NN\n",
      "in              ADP        IN\n",
      "ML              PROPN      NNP\n",
      "systems         NOUN       NNS\n",
      ".               PUNCT      .\n",
      "\n",
      "               SPACE      _SP\n"
     ]
    }
   ],
   "source": [
    "# 3. POS Tagging (spaCy)\n",
    "\n",
    "doc = nlp(text)\n",
    "print(\"3. POS Tagging:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<15} {token.pos_:<10} {token.tag_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5b86ed5-0e34-465b-b3ae-b12fa71a032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Named Entities:\n",
      "ML                   -> ORG\n",
      "ML                   -> ORG\n",
      "ML                   -> ORG\n",
      "AI                   -> GPE\n",
      "ML                   -> ORG\n",
      "ML                   -> ORG\n"
     ]
    }
   ],
   "source": [
    "# 4. Named Entity Recognition (NER)\n",
    "\n",
    "print(\"4. Named Entities:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:<20} -> {ent.label_}\")\n",
    "\n",
    "\n",
    "# ORG → Organization (companies, institutions, agencies, etc.)\n",
    "# Example: Google, UNICEF, Microsoft\n",
    "\n",
    "# GPE → Geo-Political Entity (countries, cities, states, regions)\n",
    "# Example: India, New York, Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "131cc948-bdad-43e7-a4d4-25352bd7dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. N-gram Generation (Bigrams & Trigrams)\n",
    "bigrams = list(ngrams(filtered_tokens, 2))\n",
    "trigrams = list(ngrams(filtered_tokens, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c41bc725-54bb-49f1-98c0-ce519aaf5ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Bigrams:\n",
      "\n",
      "[('ML', 'model'), ('model', 'monitoring'), ('monitoring', 'practice'), ('practice', 'tracking'), ('tracking', 'performance'), ('performance', 'ML'), ('ML', 'models'), ('models', 'production'), ('production', 'identify'), ('identify', 'potential'), ('potential', 'issues'), ('issues', 'add'), ('add', 'negative'), ('negative', 'business'), ('business', 'value'), ('value', 'practices'), ('practices', 'help'), ('help', 'proactively'), ('proactively', 'monitor'), ('monitor', 'prediction'), ('prediction', 'quality'), ('quality', 'issues'), ('issues', 'data'), ('data', 'relevance'), ('relevance', 'model'), ('model', 'accuracy'), ('accuracy', 'bias'), ('bias', 'ML'), ('ML', 'monitoring'), ('monitoring', 'constitutes'), ('constitutes', 'subset'), ('subset', 'AI'), ('AI', 'observability'), ('observability', 'showcases'), ('showcases', 'bigger'), ('bigger', 'picture'), ('picture', 'testing'), ('testing', 'validation'), ('validation', 'explainability'), ('explainability', 'exploring'), ('exploring', 'unforeseen'), ('unforeseen', 'failure'), ('failure', 'modes'), ('modes', 'performance'), ('performance', 'ML'), ('ML', 'models'), ('models', 'starts'), ('starts', 'degrading'), ('degrading', 'time'), ('time', 'due'), ('due', 'data'), ('data', 'inconsistencies'), ('inconsistencies', 'skews'), ('skews', 'drifts'), ('drifts', 'making'), ('making', 'deployed'), ('deployed', 'models'), ('models', 'inaccurate'), ('inaccurate', 'irrelevant'), ('irrelevant', 'Appropriate'), ('Appropriate', 'ML'), ('ML', 'monitoring'), ('monitoring', 'helps'), ('helps', 'identify'), ('identify', 'precisely'), ('precisely', 'model'), ('model', 'performance'), ('performance', 'started'), ('started', 'diminishing'), ('diminishing', 'proactive'), ('proactive', 'monitoring'), ('monitoring', 'helps'), ('helps', 'take'), ('take', 'required'), ('required', 'actions'), ('actions', 'like'), ('like', 'retraining'), ('retraining', 'models'), ('models', 'replacing'), ('replacing', 'models'), ('models', 'helps'), ('helps', 'foster'), ('foster', 'trust'), ('trust', 'ML'), ('ML', 'systems')]\n",
      "\n",
      "\n",
      "5. Trigrams:\n",
      "\n",
      "[('ML', 'model', 'monitoring'), ('model', 'monitoring', 'practice'), ('monitoring', 'practice', 'tracking'), ('practice', 'tracking', 'performance'), ('tracking', 'performance', 'ML'), ('performance', 'ML', 'models'), ('ML', 'models', 'production'), ('models', 'production', 'identify'), ('production', 'identify', 'potential'), ('identify', 'potential', 'issues'), ('potential', 'issues', 'add'), ('issues', 'add', 'negative'), ('add', 'negative', 'business'), ('negative', 'business', 'value'), ('business', 'value', 'practices'), ('value', 'practices', 'help'), ('practices', 'help', 'proactively'), ('help', 'proactively', 'monitor'), ('proactively', 'monitor', 'prediction'), ('monitor', 'prediction', 'quality'), ('prediction', 'quality', 'issues'), ('quality', 'issues', 'data'), ('issues', 'data', 'relevance'), ('data', 'relevance', 'model'), ('relevance', 'model', 'accuracy'), ('model', 'accuracy', 'bias'), ('accuracy', 'bias', 'ML'), ('bias', 'ML', 'monitoring'), ('ML', 'monitoring', 'constitutes'), ('monitoring', 'constitutes', 'subset'), ('constitutes', 'subset', 'AI'), ('subset', 'AI', 'observability'), ('AI', 'observability', 'showcases'), ('observability', 'showcases', 'bigger'), ('showcases', 'bigger', 'picture'), ('bigger', 'picture', 'testing'), ('picture', 'testing', 'validation'), ('testing', 'validation', 'explainability'), ('validation', 'explainability', 'exploring'), ('explainability', 'exploring', 'unforeseen'), ('exploring', 'unforeseen', 'failure'), ('unforeseen', 'failure', 'modes'), ('failure', 'modes', 'performance'), ('modes', 'performance', 'ML'), ('performance', 'ML', 'models'), ('ML', 'models', 'starts'), ('models', 'starts', 'degrading'), ('starts', 'degrading', 'time'), ('degrading', 'time', 'due'), ('time', 'due', 'data'), ('due', 'data', 'inconsistencies'), ('data', 'inconsistencies', 'skews'), ('inconsistencies', 'skews', 'drifts'), ('skews', 'drifts', 'making'), ('drifts', 'making', 'deployed'), ('making', 'deployed', 'models'), ('deployed', 'models', 'inaccurate'), ('models', 'inaccurate', 'irrelevant'), ('inaccurate', 'irrelevant', 'Appropriate'), ('irrelevant', 'Appropriate', 'ML'), ('Appropriate', 'ML', 'monitoring'), ('ML', 'monitoring', 'helps'), ('monitoring', 'helps', 'identify'), ('helps', 'identify', 'precisely'), ('identify', 'precisely', 'model'), ('precisely', 'model', 'performance'), ('model', 'performance', 'started'), ('performance', 'started', 'diminishing'), ('started', 'diminishing', 'proactive'), ('diminishing', 'proactive', 'monitoring'), ('proactive', 'monitoring', 'helps'), ('monitoring', 'helps', 'take'), ('helps', 'take', 'required'), ('take', 'required', 'actions'), ('required', 'actions', 'like'), ('actions', 'like', 'retraining'), ('like', 'retraining', 'models'), ('retraining', 'models', 'replacing'), ('models', 'replacing', 'models'), ('replacing', 'models', 'helps'), ('models', 'helps', 'foster'), ('helps', 'foster', 'trust'), ('foster', 'trust', 'ML'), ('trust', 'ML', 'systems')]\n"
     ]
    }
   ],
   "source": [
    "print(\"5. Bigrams:\\n\")\n",
    "print(bigrams)\n",
    "print(\"\\n\\n5. Trigrams:\\n\")\n",
    "print(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88de9ac6-3a2e-4889-887d-90b741945078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e109b7f-5316-4da4-bbec-d9c478fe447f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf218537-63ab-4c6c-a895-efac5627718f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9f4de2e-c387-4061-93e7-5a34de79fb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Pramoda A\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Pramoda A\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Pramoda A S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "Original Text:\n",
      "Apple is looking at buying U.K. startup for $1 billion. Steve Jobs founded Apple in 1976.\n",
      "--------------------------------------------------\n",
      "1. Tokenization:\n",
      "['Apple', 'is', 'looking', 'at', 'buying', 'U.K.', 'startup', 'for', '$', '1', 'billion', '.', 'Steve', 'Jobs', 'founded', 'Apple', 'in', '1976', '.']\n",
      "--------------------------------------------------\n",
      "2. Stopword Removal:\n",
      "['Apple', 'looking', 'buying', 'startup', 'billion', 'Steve', 'Jobs', 'founded', 'Apple']\n",
      "--------------------------------------------------\n",
      "3. POS Tagging:\n",
      "[('Apple', 'NNP'), ('looking', 'VBG'), ('buying', 'VBG'), ('startup', 'NN'), ('billion', 'CD'), ('Steve', 'NNP'), ('Jobs', 'NNP'), ('founded', 'VBD'), ('Apple', 'NNP')]\n",
      "--------------------------------------------------\n",
      "4. Named Entity Recognition (NER):\n",
      "Apple -> ORG\n",
      "U.K. -> GPE\n",
      "$1 billion -> MONEY\n",
      "Steve Jobs -> PERSON\n",
      "Apple -> ORG\n",
      "1976 -> DATE\n",
      "--------------------------------------------------\n",
      "5. N-grams:\n",
      "Bigrams: [('Apple', 'looking'), ('looking', 'buying'), ('buying', 'startup'), ('startup', 'billion'), ('billion', 'Steve'), ('Steve', 'Jobs'), ('Jobs', 'founded'), ('founded', 'Apple')]\n",
      "Trigrams: [('Apple', 'looking', 'buying'), ('looking', 'buying', 'startup'), ('buying', 'startup', 'billion'), ('startup', 'billion', 'Steve'), ('billion', 'Steve', 'Jobs'), ('Steve', 'Jobs', 'founded'), ('Jobs', 'founded', 'Apple')]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# NLP Demonstration Program\n",
    "# Covers Tokenization, Stopword Removal, POS Tagging, NER, and N-grams\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Download required resources (only first time)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "# Load Spacy model for NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion. Steve Jobs founded Apple in 1976.\"\n",
    "\n",
    "print(\"Original Text:\")\n",
    "print(text)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 1. Tokenization\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(\"1. Tokenization:\")\n",
    "print(tokens)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 2. Stopword Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word.isalpha()]\n",
    "print(\"2. Stopword Removal:\")\n",
    "print(filtered_tokens)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 3. POS Tagging\n",
    "pos_tags = nltk.pos_tag(filtered_tokens)\n",
    "print(\"3. POS Tagging:\")\n",
    "print(pos_tags)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 4. Named Entity Recognition (NER) using Spacy\n",
    "doc = nlp(text)\n",
    "print(\"4. Named Entity Recognition (NER):\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"->\", ent.label_)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 5. N-grams Generation (Bigrams and Trigrams)\n",
    "print(\"5. N-grams:\")\n",
    "bigrams = list(ngrams(filtered_tokens, 2))\n",
    "trigrams = list(ngrams(filtered_tokens, 3))\n",
    "print(\"Bigrams:\", bigrams)\n",
    "print(\"Trigrams:\", trigrams)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ede0626-de68-4e8a-97d0-4a92905a215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Apple', 'is', 'looking', 'to', 'buy', 'U.K.', 'startup', 'for', '$', '1', 'billion', '.']\n",
      "Filtered Tokens: ['Apple', 'looking', 'buy', 'U.K.', 'startup', '$', '1', 'billion', '.']\n",
      "POS Tags: [('Apple', 'NNP'), ('is', 'VBZ'), ('looking', 'VBG'), ('to', 'TO'), ('buy', 'VB'), ('U.K.', 'NNP'), ('startup', 'NN'), ('for', 'IN'), ('$', '$'), ('1', 'CD'), ('billion', 'CD'), ('.', '.')]\n",
      "Named Entities:\n",
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n",
      "Bigrams: [('Apple', 'is'), ('is', 'looking'), ('looking', 'to'), ('to', 'buy'), ('buy', 'U.K.'), ('U.K.', 'startup'), ('startup', 'for'), ('for', '$'), ('$', '1'), ('1', 'billion'), ('billion', '.')]\n",
      "Trigrams: [('Apple', 'is', 'looking'), ('is', 'looking', 'to'), ('looking', 'to', 'buy'), ('to', 'buy', 'U.K.'), ('buy', 'U.K.', 'startup'), ('U.K.', 'startup', 'for'), ('startup', 'for', '$'), ('for', '$', '1'), ('$', '1', 'billion'), ('1', 'billion', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Sample text\n",
    "text = \"Apple is looking to buy U.K. startup for $1 billion.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Stopword removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "print(\"Filtered Tokens:\", filtered_tokens)\n",
    "\n",
    "# POS Tagging\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(\"POS Tags:\", pos_tags)\n",
    "\n",
    "# NER\n",
    "doc = nlp(text)\n",
    "print(\"Named Entities:\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# N-grams generation\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "trigrams = list(ngrams(tokens, 3))\n",
    "print(\"Bigrams:\", bigrams)\n",
    "print(\"Trigrams:\", trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6e7ea5-3328-454a-9c3c-fc1b643c5d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64780db0-a5bf-41ac-95c6-489f735f8d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a6ce3a-d8db-416a-9aee-e46c9953a3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38883f-df33-4aa1-8f23-d467fb22757d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6b11e-7c0f-4b1b-898c-7b7bae1ec9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401bb69c-f22d-4617-951c-94eb709ce34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
